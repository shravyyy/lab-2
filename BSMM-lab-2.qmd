---
title: "BSMM-lab-2"
subtitle: "BSMM 8740 Fall 2023"
author: "Shravya Pusa"
date: "2023-09-28"
format: html
editor: visual
self-contained: true
---

## Setup

Load packages and data:

```{r load-pkg-data}
#| message: false
the_tate <- readr::read_delim("data/the-tate-collection.csv", ";", escape_double = FALSE, trim_ws = TRUE)
the_tate_artists <- readr::read_csv("data/the-tate-artists.csv")
```

```{r Install packages}
install.packages("magrittr")     # the pipe
install.packages("tidyverse")
install.packages("tidymodels")
install.packages("gt")
install.packages("gtExtras")  
install.packages("DataExplorer")  


```

```{r Load required Packages}

library(magrittr)     # the pipe
library(tidyverse)    # for data wrangling + visualization
library(tidymodels)   # for modeling
library(gt)           # for making display tables
library(gtExtras)     # helper functions for beautiful tables
library(DataExplorer) #
library(dplyr)


```

## Exercises

### Exercise 1

```{r}
num_unique_artists <- the_tate %>%
  distinct(artistId) 

distinct_count <- the_tate %>%
  summarize(distinct_count = n_distinct(artistId))

distinct_count
```

```{r}
the_tate_cleaned <- the_tate %>%
  na.omit()

```

```{r}
the_tate_cleaned
```

```{r}
result <- the_tate_cleaned %>%
  summarize(min_year = min(year),
            max_year = max(year),
            min_aquisition_year=min(acquisitionYear),
            max_aquisition_year=max(acquisitionYear))
```

```{r}
the_tate_cleaned$year <- as.numeric(the_tate_cleaned$year)

```

```{r}
the_tate_cleaned$acquisitionYear <- as.numeric(the_tate_cleaned$acquisitionYear)
```

```{r}
# Check for missing values in the "year" column
any(is.na(the_tate_cleaned$year))

```

```{r}
result_1 <- the_tate_cleaned %>%
  summarize(min_year = min(year),
            max_year = max(year),
            min_aquisition_year=min(acquisitionYear),
            max_aquisition_year=max(acquisitionYear))
```

```{r}
print(result_1)
```

The `the_tate` dataset has \_3342\_\_ unique artists who worked from \_1900\_\_ to \_2000\_\_. The works were acquired between the years \_1900\_\_ and \_2009\_\_.

### Exercise 2

How number of works with missing dates is 5397\_\_.

```{r}
the_tate

# Count the number of works with missing dates
missing_dates_count <- sum(is.na(the_tate$year))
print(missing_dates_count)
```

The number of artists whose works have missing dates is \_462\_.

```{r}
num_artists_with_missing_dates <- the_tate %>%
  filter(is.na(year)) %>%
  distinct(artistId) %>%
  nrow()
print(num_artists_with_missing_dates)
```

It would require resolving missing year data for only \_11\_ artists resolve resolve at least 50% of the missing data.

```{r}
library(dplyr)
library(tibble)

missing_dates_by_artist <- the_tate %>%
  filter(is.na(year)) %>%
  group_by(artistId) %>%
  tally() %>%
  arrange(desc(n)) %>%
  as_tibble()

```

```{r}
missing_dates_by_artist
```

```{r}
missing_dates_by_artist <- missing_dates_by_artist %>%
  mutate(
    percent_of_total = (n / sum(n)) * 100,
    cumulative_percent = cumsum(percent_of_total)
  )


missing_dates_by_artist
```

```{r}
required_artists <- 0
cumulative_percent_threshold <- 50

for (i in 1:nrow(missing_dates_by_artist)) {
  if (missing_dates_by_artist$cumulative_percent[i] >= cumulative_percent_threshold) {
    required_artists <- i
    break
  }
}

required_artists

```

The missing year data likely to be classified as \_\_\_\_.

### Exercise 3

```{r}
top_10_artists <- the_tate %>%
  group_by(artistId) %>%
  summarize(id = n()) %>%
  arrange(desc(id)) %>%
  head(10)

top_10_artists_names <- inner_join(top_10_artists, the_tate_artists, by = c("artistId" = "id"))

```

```{r}
top_10_artists
```

The artist with the most works in the Tate collection is \_\_Turner, Joseph\_.

The artist with the tenth-most works in the Tate collection is \_Warhol, Andy\_\_.

### Exercise 4

```{r}
greatest_number_of_works <- the_tate %>%
  group_by(artistId) %>%
  tally() %>%
  arrange(desc(n)) %>%
  as_tibble()
greatest_number_of_works <- greatest_number_of_works %>%
  mutate(
    percent_of_total = (n / sum(n)) * 100,
    cumulative_percent = cumsum(percent_of_total)
  )
print(greatest_number_of_works)
```

The artist with the greatest number of works in the Tate collection represent \_56.9\_\_% of the total number of works

### Exercise 5

There are \_23705\_ duplicate artist-title pairs

```{r}
library(dplyr)

the_tate_tibble <- as_tibble(the_tate)

# Select the columns for artist and title and count the number of rows
num_rows <- the_tate_tibble %>%
  select(artist, title) %>%
  nrow()

# Print the count of rows
cat("Number of Rows: ", num_rows, "\n")

# Select the columns for artist and title, then count the distinct artist-title pairs
num_distinct_pairs <- the_tate_tibble %>%
  select(artist, title) %>%
  distinct() %>%
  nrow()

# Print the count of distinct artist-title pairs
cat("Number of Distinct Artist-Title Pairs: ", num_distinct_pairs, "\n")
Duplicate_artist_title_pairs <- num_rows-num_distinct_pairs

print(Duplicate_artist_title_pairs)

```

### Exercise 6

The artist with the largest work in the tate collection is \_29021\_\_

```{r}
# Calculate the area in cm^2 and add it as a new column
the_tate <- the_tate %>%
  mutate(area_cm2 = height * width * 0.01)
```

```{r}
# Select artist, title, and area columns and remove NA values
selected_data <- the_tate %>%
  select(artistId, title, area_cm2) %>%
  drop_na()

# Order the works by area
ordered_data <- selected_data %>%
  arrange(area_cm2)

# Find the largest artwork in the collection
largest_artwork <- ordered_data %>%
  slice_tail(n = 1)

# Find the smallest artwork in the collection
smallest_artwork <- ordered_data %>%
  slice_head(n = 1)

# Print the largest and smallest artworks

print(largest_artwork)

print(smallest_artwork)


```

The artist with the smallest work in the collection is \_\_1624()\_. The smallest work has area \_\_2.37\_ $\text{cm}^2$

### Exercise 7

```{r}

# Left join the tables on the artistId, id column
the_tate_artists_join <- left_join(the_tate, the_tate_artists, by = c("artistId"="id"))

# Drop rows with NA gender values
the_tate_artists_join <- the_tate_artists_join %>%
  filter(!is.na(gender))

# Group by gender
grouped_data <- the_tate_artists_join %>%
  group_by(gender)

# Show the resulting table
grouped_data
```

### Exercise 8

```{r}

SPX_Data <- read.csv("data/SPX_HistoricalData_1692322132002.csv")

```

```{r}

SPX_Data <- SPX_Data %>%
  rename(close_last = Close.Last)
# Create a new column 'previous_close/lost' using lag() for the 'id' column
SPX_Data <- SPX_Data %>%
  mutate(previous_CloseLost = lag(Close.Last))

# Print the resulting dataframe

```

```{r}
SPX_Data
```

```{r}
SPX_Data <- SPX_Data %>%
  mutate(ri = log(Close.Last/previous_CloseLost))

SPX_Data <- SPX_Data %>%
  mutate(var_ri = ri^2)

```

```{r}
#SPX_Data_summary <- SPX_Data %>%
#  mutate(date = mdy(date))

# Extract the year from the 'date' column
#SPX_Data_summary <- SPX_Data_summary %>%
#  mutate(year = year(date))

SPX_Data_summary <- SPX_Data %>%
  mutate(year = substr(date, 7, 10))
#df$year <- substr(df$date, start_index, end_index)


SPX_Data_date <- SPX_Data

```

```{r}
SPX_Data_date$year <- substr(SPX_Data_date$Date, 7, 10)

```

```{r}
summary_SPX_Data <- SPX_Data_date %>%
  group_by(year) %>%
  summarize(
    annual_return = mean(ri),
    annual_std_dev = sd(ri)
  ) %>%
  ungroup()
```

```{}
```

The annual return in the SPX price in 2020 was --0.05\_\_\_%.

The corresponding price volatility was \_\_\_%.

### Exercise 9

The period volatility was \_\_\_.\_%

### 
